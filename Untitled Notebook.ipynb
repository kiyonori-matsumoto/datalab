{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting gensim\n",
      "  Downloading gensim-3.2.0-cp35-cp35m-manylinux1_x86_64.whl (15.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 15.9MB 78kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.5/dist-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.5/dist-packages (from gensim)\n",
      "Collecting scipy>=0.18.1 (from gensim)\n",
      "  Downloading scipy-1.0.0-cp35-cp35m-manylinux1_x86_64.whl (49.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 49.6MB 24kB/s \n",
      "\u001b[?25hCollecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading smart_open-1.5.6.tar.gz\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 1.0MB/s \n",
      "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.5/dist-packages (from smart-open>=1.2.1->gensim)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "  Downloading boto3-1.5.14-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 5.8MB/s \n",
      "\u001b[?25hCollecting botocore<1.9.0,>=1.8.28 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading botocore-1.8.28-py2.py3-none-any.whl (4.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.0MB 340kB/s \n",
      "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading s3transfer-0.1.12-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 7.3MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.5/dist-packages (from botocore<1.9.0,>=1.8.28->boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.5/dist-packages (from botocore<1.9.0,>=1.8.28->boto3->smart-open>=1.2.1->gensim)\n",
      "Building wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/36/48/35/97efc2bd1b233627131c9a936c9de23681846db707b907d353\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/31/9c/20/996d65ca104cbca940b1b053299b68459391c01c774d073126\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: scipy, boto, bz2file, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "  Found existing installation: scipy 0.18.0\n",
      "    Uninstalling scipy-0.18.0:\n",
      "      Successfully uninstalled scipy-0.18.0\n",
      "Successfully installed boto-2.48.0 boto3-1.5.14 botocore-1.8.28 bz2file-0.98 gensim-3.2.0 jmespath-0.9.3 s3transfer-0.1.12 scipy-1.0.0 smart-open-1.5.6\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras\n",
    "!pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from gensim import corpora\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_of_sequence = 10\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for file in ['sample.txt', '087388_hanrei.txt']:\n",
    "  with open(file, 'r') as fin:\n",
    "    lines = fin.readlines()\n",
    "  lines = [unicodedata.normalize('NFKC', line).replace(' ', '').replace('\\t', ' ').rstrip() for line in lines]\n",
    "  text = list(''.join(lines))\n",
    "  texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-01-17 16:09:04,593] {dictionary.py:116} INFO - adding document #0 to Dictionary(0 unique tokens: [])\n",
      "[2018-01-17 16:09:04,610] {dictionary.py:123} INFO - built Dictionary(762 unique tokens: ['委', '不', '制', '川', '色']...) from 2 documents (total 14096 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "length = len(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=(length_of_sequence, len(dictionary.keys()))))\n",
    "model.add(Dense(length))\n",
    "model.add(Activation(\"softmax\"))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for text in texts:\n",
    "  for i in range(0, len(text) - length_of_sequence, 1):\n",
    "    X.append(text[i:i+length_of_sequence])\n",
    "    y.append(text[i+length_of_sequence])\n",
    "\n",
    "  length = len(dictionary.keys())\n",
    "\n",
    "X = [np_utils.to_categorical(dictionary.doc2idx(d), length) for d in X]\n",
    "y = [np_utils.to_categorical(dictionary.doc2idx([d])[0], length) for d in y]\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14076, 10, 762)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14076/14076 [==============================] - 9s 668us/step - loss: 5.7148\n",
      "Epoch 2/100\n",
      "14076/14076 [==============================] - 9s 625us/step - loss: 5.2752\n",
      "Epoch 3/100\n",
      "14076/14076 [==============================] - 9s 626us/step - loss: 5.2326\n",
      "Epoch 4/100\n",
      "14076/14076 [==============================] - 9s 629us/step - loss: 5.1797\n",
      "Epoch 5/100\n",
      "14076/14076 [==============================] - 9s 628us/step - loss: 5.0801\n",
      "Epoch 6/100\n",
      "14076/14076 [==============================] - 9s 630us/step - loss: 4.9106\n",
      "Epoch 7/100\n",
      "14076/14076 [==============================] - 9s 632us/step - loss: 4.7082\n",
      "Epoch 8/100\n",
      "14076/14076 [==============================] - 9s 634us/step - loss: 4.4915\n",
      "Epoch 9/100\n",
      "14076/14076 [==============================] - 9s 634us/step - loss: 4.2681\n",
      "Epoch 10/100\n",
      "14076/14076 [==============================] - 9s 637us/step - loss: 4.0509\n",
      "Epoch 11/100\n",
      "14076/14076 [==============================] - 9s 639us/step - loss: 3.8338\n",
      "Epoch 12/100\n",
      "14076/14076 [==============================] - 9s 642us/step - loss: 3.6338\n",
      "Epoch 13/100\n",
      "14076/14076 [==============================] - 9s 643us/step - loss: 3.4356\n",
      "Epoch 14/100\n",
      "14076/14076 [==============================] - 9s 648us/step - loss: 3.2546\n",
      "Epoch 15/100\n",
      "14076/14076 [==============================] - 9s 646us/step - loss: 3.0738\n",
      "Epoch 16/100\n",
      "14076/14076 [==============================] - 9s 646us/step - loss: 2.8998\n",
      "Epoch 17/100\n",
      "14076/14076 [==============================] - 9s 651us/step - loss: 2.7434\n",
      "Epoch 18/100\n",
      "14076/14076 [==============================] - 9s 650us/step - loss: 2.5927\n",
      "Epoch 19/100\n",
      "14076/14076 [==============================] - 9s 652us/step - loss: 2.4386\n",
      "Epoch 20/100\n",
      "14076/14076 [==============================] - 9s 652us/step - loss: 2.2884\n",
      "Epoch 21/100\n",
      "14076/14076 [==============================] - 9s 654us/step - loss: 2.1478\n",
      "Epoch 22/100\n",
      "14076/14076 [==============================] - 9s 655us/step - loss: 2.0159\n",
      "Epoch 23/100\n",
      "14076/14076 [==============================] - 9s 663us/step - loss: 1.9012\n",
      "Epoch 24/100\n",
      "14076/14076 [==============================] - 9s 656us/step - loss: 1.7728\n",
      "Epoch 25/100\n",
      "14076/14076 [==============================] - 9s 658us/step - loss: 1.6522\n",
      "Epoch 26/100\n",
      "14076/14076 [==============================] - 9s 659us/step - loss: 1.5324\n",
      "Epoch 27/100\n",
      "14076/14076 [==============================] - 9s 662us/step - loss: 1.4236\n",
      "Epoch 28/100\n",
      "14076/14076 [==============================] - 9s 665us/step - loss: 1.3228\n",
      "Epoch 29/100\n",
      "14076/14076 [==============================] - 9s 664us/step - loss: 1.2176\n",
      "Epoch 30/100\n",
      "14076/14076 [==============================] - 9s 665us/step - loss: 1.1207\n",
      "Epoch 31/100\n",
      "14076/14076 [==============================] - 9s 666us/step - loss: 1.0307\n",
      "Epoch 32/100\n",
      "14076/14076 [==============================] - 9s 668us/step - loss: 0.9471\n",
      "Epoch 33/100\n",
      "14076/14076 [==============================] - 9s 670us/step - loss: 0.8667\n",
      "Epoch 34/100\n",
      "14076/14076 [==============================] - 9s 671us/step - loss: 0.7929\n",
      "Epoch 35/100\n",
      "14076/14076 [==============================] - 9s 675us/step - loss: 0.7187\n",
      "Epoch 36/100\n",
      "14076/14076 [==============================] - 9s 675us/step - loss: 0.6523\n",
      "Epoch 37/100\n",
      "14076/14076 [==============================] - 10s 676us/step - loss: 0.5928\n",
      "Epoch 38/100\n",
      "14076/14076 [==============================] - 10s 677us/step - loss: 0.5288\n",
      "Epoch 39/100\n",
      "14076/14076 [==============================] - 10s 679us/step - loss: 0.4786\n",
      "Epoch 40/100\n",
      "14076/14076 [==============================] - 10s 682us/step - loss: 0.4256\n",
      "Epoch 41/100\n",
      "14076/14076 [==============================] - 10s 688us/step - loss: 0.3789\n",
      "Epoch 42/100\n",
      "14076/14076 [==============================] - 10s 680us/step - loss: 0.3388\n",
      "Epoch 43/100\n",
      "14076/14076 [==============================] - 10s 683us/step - loss: 0.3081\n",
      "Epoch 44/100\n",
      "14076/14076 [==============================] - 10s 684us/step - loss: 0.2776\n",
      "Epoch 45/100\n",
      "14076/14076 [==============================] - 10s 686us/step - loss: 0.2501\n",
      "Epoch 46/100\n",
      "14076/14076 [==============================] - 10s 687us/step - loss: 0.2243\n",
      "Epoch 47/100\n",
      "14076/14076 [==============================] - 10s 688us/step - loss: 0.2026\n",
      "Epoch 48/100\n",
      "14076/14076 [==============================] - 10s 691us/step - loss: 0.1847\n",
      "Epoch 49/100\n",
      "14076/14076 [==============================] - 10s 690us/step - loss: 0.1689\n",
      "Epoch 50/100\n",
      "14076/14076 [==============================] - 10s 690us/step - loss: 0.1518\n",
      "Epoch 51/100\n",
      "14076/14076 [==============================] - 10s 693us/step - loss: 0.1403\n",
      "Epoch 52/100\n",
      "14076/14076 [==============================] - 10s 695us/step - loss: 0.1286\n",
      "Epoch 53/100\n",
      "14076/14076 [==============================] - 10s 696us/step - loss: 0.1192\n",
      "Epoch 54/100\n",
      "14076/14076 [==============================] - 10s 703us/step - loss: 0.1103\n",
      "Epoch 55/100\n",
      "14076/14076 [==============================] - 10s 700us/step - loss: 0.1039\n",
      "Epoch 56/100\n",
      "14076/14076 [==============================] - 10s 704us/step - loss: 0.0964\n",
      "Epoch 57/100\n",
      "14076/14076 [==============================] - 10s 704us/step - loss: 0.0913\n",
      "Epoch 58/100\n",
      "14076/14076 [==============================] - 10s 701us/step - loss: 0.0851\n",
      "Epoch 59/100\n",
      "14076/14076 [==============================] - 10s 712us/step - loss: 0.0816\n",
      "Epoch 60/100\n",
      "14076/14076 [==============================] - 10s 713us/step - loss: 0.0771\n",
      "Epoch 61/100\n",
      "14076/14076 [==============================] - 10s 710us/step - loss: 0.0742\n",
      "Epoch 62/100\n",
      "14076/14076 [==============================] - 10s 711us/step - loss: 0.0703\n",
      "Epoch 63/100\n",
      "14076/14076 [==============================] - 10s 712us/step - loss: 0.0677\n",
      "Epoch 64/100\n",
      "14076/14076 [==============================] - 10s 712us/step - loss: 0.0644\n",
      "Epoch 65/100\n",
      "14076/14076 [==============================] - 10s 712us/step - loss: 0.0608\n",
      "Epoch 66/100\n",
      "14076/14076 [==============================] - 10s 713us/step - loss: 0.0600\n",
      "Epoch 67/100\n",
      "14076/14076 [==============================] - 10s 716us/step - loss: 0.0564\n",
      "Epoch 68/100\n",
      "14076/14076 [==============================] - 10s 715us/step - loss: 0.0555\n",
      "Epoch 69/100\n",
      "14076/14076 [==============================] - 10s 713us/step - loss: 0.0534\n",
      "Epoch 70/100\n",
      "14076/14076 [==============================] - 10s 713us/step - loss: 0.0523\n",
      "Epoch 71/100\n",
      "14076/14076 [==============================] - 10s 714us/step - loss: 0.0511\n",
      "Epoch 72/100\n",
      "14076/14076 [==============================] - 11s 747us/step - loss: 0.0507\n",
      "Epoch 73/100\n",
      "14076/14076 [==============================] - 12s 860us/step - loss: 0.0497\n",
      "Epoch 74/100\n",
      "14076/14076 [==============================] - 10s 731us/step - loss: 0.0471\n",
      "Epoch 75/100\n",
      "14076/14076 [==============================] - 11s 767us/step - loss: 0.0448\n",
      "Epoch 76/100\n",
      "14076/14076 [==============================] - 11s 750us/step - loss: 0.0441\n",
      "Epoch 77/100\n",
      "14076/14076 [==============================] - 10s 741us/step - loss: 0.0443\n",
      "Epoch 78/100\n",
      "14076/14076 [==============================] - 10s 736us/step - loss: 0.0419\n",
      "Epoch 79/100\n",
      "14076/14076 [==============================] - 10s 714us/step - loss: 0.0428\n",
      "Epoch 80/100\n",
      "14076/14076 [==============================] - 10s 725us/step - loss: 0.0434\n",
      "Epoch 81/100\n",
      "14076/14076 [==============================] - 10s 720us/step - loss: 0.0438\n",
      "Epoch 82/100\n",
      "14076/14076 [==============================] - 10s 706us/step - loss: 0.0469\n",
      "Epoch 83/100\n",
      "14076/14076 [==============================] - 10s 698us/step - loss: 0.0453\n",
      "Epoch 84/100\n",
      "14076/14076 [==============================] - 10s 700us/step - loss: 0.0459\n",
      "Epoch 85/100\n",
      "14076/14076 [==============================] - 10s 699us/step - loss: 0.0458\n",
      "Epoch 86/100\n",
      "14076/14076 [==============================] - 10s 699us/step - loss: 0.0421\n",
      "Epoch 87/100\n",
      "14076/14076 [==============================] - 10s 698us/step - loss: 0.0399\n",
      "Epoch 88/100\n",
      "14076/14076 [==============================] - 10s 697us/step - loss: 0.0393\n",
      "Epoch 89/100\n",
      "14076/14076 [==============================] - 10s 700us/step - loss: 0.0375\n",
      "Epoch 90/100\n",
      "14076/14076 [==============================] - 10s 697us/step - loss: 0.0350\n",
      "Epoch 91/100\n",
      "14076/14076 [==============================] - 10s 745us/step - loss: 0.0327\n",
      "Epoch 92/100\n",
      "14076/14076 [==============================] - 10s 701us/step - loss: 0.0314\n",
      "Epoch 93/100\n",
      "14076/14076 [==============================] - 10s 704us/step - loss: 0.0316\n",
      "Epoch 94/100\n",
      "14076/14076 [==============================] - 10s 707us/step - loss: 0.0304\n",
      "Epoch 95/100\n",
      "14076/14076 [==============================] - 10s 723us/step - loss: 0.0300\n",
      "Epoch 96/100\n",
      "14076/14076 [==============================] - 11s 753us/step - loss: 0.0296\n",
      "Epoch 97/100\n",
      "14076/14076 [==============================] - 10s 723us/step - loss: 0.0311\n",
      "Epoch 98/100\n",
      "14076/14076 [==============================] - 10s 710us/step - loss: 0.0307\n",
      "Epoch 99/100\n",
      "14076/14076 [==============================] - 10s 740us/step - loss: 0.0305\n",
      "Epoch 100/100\n",
      "14076/14076 [==============================] - 10s 745us/step - loss: 0.0327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dd62fd1d0>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=n_hidden, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['を', 0.8119119], ['当', 0.06893732], ['中', 0.01861194], ['仕', 0.0122161], ['だ', 0.01088236]]\n",
      "[['を', 0.37895972], ['た', 0.097140655], ['り', 0.09654909], ['う', 0.09486117], ['け', 0.07793005]]\n",
      "[['け', 0.8333616], ['た', 0.048729002], ['り', 0.028086955], ['続', 0.023233972], ['め', 0.01915175]]\n",
      "[['く', 0.20011428], ['け', 0.13673496], ['た', 0.1287996], ['る', 0.11015312], ['す', 0.0906597]]\n",
      "[['い', 0.48273373], ['て', 0.20626731], [',', 0.14586328], ['る', 0.0781117], ['た', 0.03821782]]\n",
      "[['る', 0.3911422], ['う', 0.33007377], ['た', 0.18765365], ['と', 0.018112484], ['て', 0.0130359335]]\n",
      "[['か', 0.48899958], ['が', 0.29351828], ['と', 0.17507848], ['認', 0.011540985], ['様', 0.007446681]]\n",
      "[['な', 0.80375177], ['が', 0.0967731], ['か', 0.043429818], ['子', 0.015952758], ['ら', 0.011998009]]\n",
      "[['で', 0.5404672], ['ど', 0.2216079], ['が', 0.11864906], ['か', 0.0866781], ['と', 0.029355574]]\n",
      "[[',', 0.9999846], ['あ', 8.536318e-06], ['ど', 1.2831852e-06], ['お', 1.155536e-06], ['き', 8.6074084e-07]]\n",
      "[['A', 0.20813166], ['e', 0.15825638], ['た', 0.09839017], ['B', 0.09149513], ['被', 0.081969805]]\n",
      "[['が', 0.7107791], ['の', 0.07946956], ['か', 0.05336835], ['客', 0.037542988], ['を', 0.03504999]]\n",
      "[[',', 0.33095378], ['顧', 0.115434214], ['得', 0.077066414], ['ひ', 0.06078264], ['威', 0.048333637]]\n",
      "[['そ', 0.75389624], ['本', 0.04716433], ['行', 0.020340635], ['と', 0.018346349], ['ま', 0.017912624]]\n",
      "[['の', 0.9966846], ['に', 0.0018691962], ['行', 0.00079749816], ['た', 9.4790725e-05], ['ほ', 8.0110294e-05]]\n",
      "[['降', 0.78231186], ['者', 0.11110832], ['行', 0.012286617], ['後', 0.0115039665], ['際', 0.0067226496]]\n",
      "[['車', 0.63361424], ['を', 0.10395678], ['は', 0.040373765], ['で', 0.03404135], ['降', 0.016214792]]\n",
      "[['を', 0.4391509], ['に', 0.2738835], ['被', 0.10810356], ['自', 0.042450234], ['が', 0.015715187]]\n",
      "[['被', 0.49941292], ['降', 0.12928689], ['し', 0.116799854], ['同', 0.07139832], ['自', 0.037194375]]\n",
      "[['害', 0.92124516], ['告', 0.041041825], ['ら', 0.03341979], ['提', 0.00082856254], ['性', 0.00080962136]]\n",
      "[['者', 0.99964607], ['人', 0.00022617652], ['に', 5.3294774e-05], ['と', 2.8100178e-05], ['が', 2.2773369e-05]]\n",
      "[['に', 0.37056392], ['が', 0.35868502], ['者', 0.16930935], ['の', 0.04577156], ['と', 0.03826674]]\n",
      "[['顔', 0.12899631], ['目', 0.12543824], ['姿', 0.101244435], ['を', 0.09279177], ['転', 0.07687788]]\n",
      "[['に', 0.79416746], ['け', 0.13305263], ['を', 0.03817446], ['引', 0.0060389647], ['る', 0.003941152]]\n",
      "[['つ', 0.30130836], ['戻', 0.16009541], ['に', 0.12386915], ['努', 0.12152371], ['出', 0.05551089]]\n",
      "[['っ', 0.9953047], ['く', 0.0010281529], ['て', 0.0008787684], ['た', 0.0008565497], ['る', 0.0005633764]]\n",
      "[['て', 0.9358068], ['た', 0.06410166], ['わ', 7.96536e-05], ['ば', 4.1633057e-06], ['っ', 2.8118986e-06]]\n",
      "[[',', 0.67601675], ['い', 0.15906163], ['(', 0.082625456], ['は', 0.036642276], ['お', 0.011883855]]\n",
      "[['被', 0.48273164], ['両', 0.2055985], ['C', 0.1434526], ['A', 0.027463516], ['B', 0.020664267]]\n",
      "[['害', 0.6420206], ['告', 0.3461635], ['は', 0.008538883], ['C', 0.00074040156], ['者', 0.00034615424]]\n"
     ]
    }
   ],
   "source": [
    "test = 1000\n",
    "text = texts[0]\n",
    "# sample_text = text[test:test+length_of_sequence]\n",
    "sample_text=list('別紙控訴人目録記載の')\n",
    "for i in range(30):\n",
    "#   print(sample_text)\n",
    "  sample = dictionary.doc2idx(list(sample_text))\n",
    "  sample = np_utils.to_categorical(sample, length)\n",
    "  sample = np.expand_dims(sample, axis=0)\n",
    "\n",
    "  result = model.predict(sample)[0]\n",
    "  print([[dictionary.get(k), result[k]] for k in np.argsort(result)[::-1][0:5]])\n",
    "  char = dictionary.get(np.argmax(result))\n",
    "  sample_text.append(char)\n",
    "  sample_text = sample_text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
